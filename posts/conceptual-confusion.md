# Conceptual confusion

Inspired by Yiqin Fu's piece on [Democracy plumbing](https://yiqinfu.github.io/posts/democracy-plumbers/)
Inspired by Kevin Munger's piece on [How to allocate scare social science resources](https://kevinmunger.substack.com/p/how-should-we-allocate-scarce-social):
    "But within the present system, conceptual confusion is inevitable. Without an agreement on what weâ€™re trying to do, we lack a coherent framework for deciding how to allocate our scarce resources."

I have often grown frustrated as a social scientist researching social media that my work felt more like a game of whack-a-mole than as steps in scientific progress. I mostly framed this as the result of being on the backfoot - of the field belated responding to the information age and struggling to keep up. And I still think that's true. But I've also come to realize that I had opted in to the game of whack-a-mole by hitting the ground running without making a plan first. As I've been forced to take a career break I now see I have the opportunity to take put down the mallet and take a more systematic approach to my work. Munger calls this the metascience approach. I'm personally not keen of his use of the term in that piece as he defines it differently to how I believe it is more appropriately being used in the hard science [link to A and Kanjun stuff]. But I agree with him that social scientists should pause to do some agenda setting before me continue on with low value niche research.

I also agree with Munger that the first step is to sort out the conceptual confusion that we currently have. The project I'm working on here explores whether the 'attention economy' can serve as a useful model on which to gain conceptual clarity.

Here's a [mindmap](https://miro.com/app/board/uXjVO0YyOII=/?share_link_id=653705587083) setting out my current thinking on these concepts.

## Problem set

1) Market competition
2) User privacy
3) Content moderation

Wu 2017 outlined how the attention economy can address competition concerns so the conceptual connection there is clear.

Competition concerns relate to user privacy as user data is collected to meet business incentives. Data is collected to improve products and ability to advertise. We have metaphors or users paying for services with their data (and their time in attention) rather than with money. See joint statement by the CMA and the ICO on the need for competition and privacy regulators to work together instead of at odds with each other.

With content moderation we move a step further away. Here we have another new challenge to an age old problem - the regulation of free expression. The wicked problem at the heart of the issue - where to draw the boundaries of what expressions are acceptable in a space - are tangential to the attention economy. The attention economy has caused these debates to flare, but it has not created them. What is unique to the attention economy is the issue of reach - of algorithmic amplification and virality bring previously impossible levels of attention to problematic content. And reach clearly relates to the attention economy - increased reach --> bringing a piece of content to the attention of more people (and often also trying to hold their attention for longer).

There is also a fourth problem related to algorithmic curation and reach that I have so far not emphasized.

4) Addiction / individual time spent

Whereas algorithmic amplification increase the breadth of user attention (e.g. the number of user viewing), other features of the attention economy (both content-based and algorithmic) are designed to increase depth of user attention (e.g. the amount of time spent per user). To increased the overall amount of attention spent the economy can both increase the number of user views per piece of content, and increase the number of pieces of content viewed per user. This is where addiction fears come in to play.

That then plays in to concerns around the effects of the content itself (e.g. teenagers being addicted to social media and it harming their mental health). This is still related to the issue of attention, but on a more philosophical level of what we spend our attention on rather than how much we spent or the opportunity costs of spending.

Open question: how does user 'engagement tie in to this'. Often platforms aren't optimising for time spent exactly but for other metrics of engagement (i.e. number of likes, comments, shares). Need to flesh out how this variety of forms of attention fits in to the Wu framework of attentional brokerage.

## Framing

1) What are we trading our attention for? [transactions and tradeoffs]
2) How much attention are we giving? [mechanisms and opportunity costs]
3) How does the content with give attention to effect us?

## Beyond the scope

Normative statements on where content moderation lines should be drawn. I certainly have my own views but think these should largely be determined by local norms on a jurisdiction basis (with a small caveat for maintaining human rights under authoritarian regimes).

Discussion of technical feasibility. I do expect to delve in to that at a latter stage when scoping out policy thinking. And there may be some instances in which my conceptual model is already shaped by my current understanding of technical capabilities and limitations. But for the most part I want to keep my model building unbiased by current state of technical solutions. This should help ensure the model ages well and that it focuses on diagnostics rather than preemptive solutions (in line with my desire to stop playing whack-a-mole).

Security. I'll probably very lightly touch on it around privacy issues but otherwise I don't think it's a unique feature or challenge of the attention economy.