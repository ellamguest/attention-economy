# Conceptual confusion

Inspired by Yiqin Fu's piece on [Democracy plumbing](https://yiqinfu.github.io/posts/democracy-plumbers/)
Inspired by Kevin Munger's piece on [How to allocate scare social science resources](https://kevinmunger.substack.com/p/how-should-we-allocate-scarce-social):
    "But within the present system, conceptual confusion is inevitable. Without an agreement on what weâ€™re trying to do, we lack a coherent framework for deciding how to allocate our scarce resources."

I have often grown frustrated as a social scientist researching social media that my work felt more like a game of whack-a-mole than as steps in scientific progress. I mostly framed this as the result of being on the backfoot - of the field belated responding to the information age and struggling to keep up. And I still think that's true. But I've also come to realize that I had opted in to the game of whack-a-mole by hitting the ground running without making a plan first. As I've been forced to take a career break I now see I have the opportunity to take put down the mallet and take a more systematic approach to my work. Munger calls this the metascience approach. I'm personally not keen of his use of the term in that piece as he defines it differently to how I believe it is more appropriately being used in the hard science [link to A and Kanjun stuff]. But I agree with him that social scientists should pause to do some agenda setting before me continue on with low value niche research.

I also agree with Munger that the first step is to sort out the conceptual confusion that we currently have. The project I'm working on here explores whether the 'attention economy' can serve as a useful model on which to gain conceptual clarity.

Here's a [mindmap](https://miro.com/app/board/uXjVO0YyOII=/?share_link_id=653705587083) setting out my current thinking on these concepts.

## Problem set

1) Market competition
2) User privacy
3) Content moderation

Wu 2017 outlined how the attention economy can address competition concerns so the conceptual connection there is clear.

Competition concerns relate to user privacy as user data is collected to meet business incentives. Data is collected to improve products and ability to advertise. We have metaphors or users paying for services with their data (and their time in attention) rather than with money. See joint statement by the CMA and the ICO on the need for competition and privacy regulators to work together instead of at odds with each other.

With content moderation we move a step further away. Here we have another new challenge to an age old problem - the regulation of free expression. The wicked problem at the heart of the issue - where to draw the boundaries of what expressions are acceptable in a space - are tangential to the attention economy. The attention economy has caused these debates to flare, but it has not created them. What is unique to the attention economy is the issue of reach - of algorithmic amplification and virality bring previously impossible levels of attention to problematic content. And reach clearly relates to the attention economy - increased reach --> bringing a piece of content to the attention of more people (and often also trying to hold their attention for longer).

There is also a fourth problem related to algorithmic curation and reach that I have so far not emphasized.

4) Addiction / individual time spent

Whereas algorithmic amplification increase the breadth of user attention (e.g. the number of user viewing), other features of the attention economy (both content-based and algorithmic) are designed to increase depth of user attention (e.g. the amount of time spent per user). To increased the overall amount of attention spent the economy can both increase the number of user views per piece of content, and increase the number of pieces of content viewed per user. This is where addiction fears come in to play.

That then plays in to concerns around the effects of the content itself (e.g. teenagers being addicted to social media and it harming their mental health). This is still related to the issue of attention, but on a more philosophical level of what we spend our attention on rather than how much we spent or the opportunity costs of spending.

Open question: how does user 'engagement tie in to this'. Often platforms aren't optimising for time spent exactly but for other metrics of engagement (i.e. number of likes, comments, shares). Need to flesh out how this variety of forms of attention fits in to the Wu framework of attentional brokerage.

## Framing

1. What are we trading our attention for? [transactions and tradeoffs]
2. How much attention are we giving? [mechanisms and opportunity costs]
3. How does the content we give attention to effect us?

Or another frame

User attention is the resource ad-based platforms use to monetize their products. Drawing on user information they extract user attention on one side of the market and sell it to advertisers on the other.

1. We need to update competition regulation to understand and address the new market dynamics of the attention economy. This should address:
   - 'Free' products,
   - Two-sided markets, and
   - User data valuation and selling
2. We need to enshrine privacy values in new legislation to address the trade-offs currently being decided by the attention economy. This must be joined up with competition regulation to address:
    - Additional consumer protection constraints, and
    - Approaches to valuing user data and users' rights to consent of selling it

Then getting in to content moderation which ties to competition because it needs a free market to improve and to privacy because users should be able to dictate to what extent content should be personalised to them based on their data.

## Why starting with competition?

Because I believe it's the gateway to getting any kind of regulation done. This is because it builds on *structures that already exist* (i.e. competition law and agencies) whereas privacy and content concerns require *building new structures*. The existing competition structures need to be updated and reinterpreted to address these new challenges. But at least we have something to start working on.

At a higher level, the fact that competition legislation exists and privacy legislation does not (at least in the US and until recently in all Western democracies) suggests where our core values and priorities lie.

Actually to be fair their are some fundamental privacy values - to private property, copyright, etc. But these don't cover our *information*, or more specifically *information about us*. If anything, free speech doctrine has set limits on our rights to protect information about ourselves, but historically this has only been a problem for famous and powerful people (e.g. tabloid media, defamation and libel, publishing private correspondence.)

I think that there is actually a fundamental, historical tensions between information privacy and free speech, that is being examined in a new light due to the attention economy's commercialization of user information. If there was a historical precedent of information privacy, targeted advertising and (to a lesser extent personalized algorithms) would not have become the norm. Instead attention brokers were from the outset able to consider user information a resource to exploit.

## Beyond the scope

Normative statements on where content moderation lines should be drawn. I certainly have my own views but think these should largely be determined by local norms on a jurisdiction basis (with a small caveat for maintaining human rights under authoritarian regimes).

Discussion of technical feasibility. I do expect to delve in to that at a latter stage when scoping out policy thinking. And there may be some instances in which my conceptual model is already shaped by my current understanding of technical capabilities and limitations. But for the most part I want to keep my model building unbiased by current state of technical solutions. This should help ensure the model ages well and that it focuses on diagnostics rather than preemptive solutions (in line with my desire to stop playing whack-a-mole).

Security. I'll probably very lightly touch on it around privacy issues but otherwise I don't think it's a unique feature or challenge of the attention economy.

Ethical of philosophical discussions around privacy rights, capitalism, market dynamics, etc. 

## A note of terminology

I'll probably use the term 'platforms' most often. This is because I want to capture more than 'social media companies' and often more than 'Big Tech'.

Find a definition of platform that I like.

I'll also use the term 'jurisdiction', where other's might use 'state' or 'nation' or 'country'. I want to avoid those nation-level words because often the regulations I'm talking about are supranational (i.e. the European Union) or subnational (i.e. US state-level). Jurisdiction is also more precise because it emphasizes a unit of legal authority - i.e. I'll talk a lot about different jurisdictions taking approaches on an issue based on their underlying values.