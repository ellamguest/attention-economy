# Privacy

What does this have to do with the attention economy?

**User information is the resource used to exploit user attention**. Platforms don't care about user data for the sake of the data. They don't care about your interests or demographics for the sake of curiosity. They care about those things because knowing more about you **better informs them how to capture your attention**.

We can question to what extent probablistic predictions based on that data are actually accurate. Getting a better sense of that accuracy could be a way of reining in the targeted advertising ecosystem and addressing privacy trade-offs. But regardless of actually accuracy, this is how the attention economy works. It is how platforms develop their products, and how the monetise their products by selling user attention to advertisers. 

My immediate intuition is that these are the mounting steps in the issue:

1. Information technologies are able to capture unprecedented amounts of user/consumer data.
2. Platforms use that data to develop their products, and in particular to personalize products to users.
3. In lieu of charging users, the advertising business model commodifies that user information. I.e. 'selling data'. D
4. The nature of the data being tracked is new (e.g. behavioral data, self-disclosed demographic and interest data).
5. The way that data can be used is increased via machine learning models, increasing the value of user data as a commodity.

In [Competition](/posts/competition.md) I discuss how platforms operate as attention brokers in a two-sided market. On the first side they offer their product to users without charge. On the second side they charge advertisers for access to users' attention.

The issue comes down to a few value judgments:

1. Does the data 'belong' to user or companies?
2. Is the value of the data proportional to the value of the service to the user? E.g. the user side valuation - is it proportion for users to pay for the product with their data.
3. Is the personal/private nature of the data proportion to what companies get from advertisers? E.g. the advertiser side valuation. But not a direct comparison because the externalities are borne by the users (i.e. privacy risks) but the transaction is between advertisers and platforms.

But what does this have to do with the attention economy?? Bring it back! recenter!

The right to privacy is itself a core issue. But I'm not a privacy rights scholar or advocate. My interest in privacy relates to the novel problems that information technologies have created. And I believe that those problems are largely (but not wholly) downstream of the attention economy. Specifically, privacy concerns are externalities of the advertising model.

To be clear there are still privacy concerns in non-advertising business models, when all user data is kept 'first party' and 'just' used to improve services. *Find a case study of a paid for company that took data collection and use too far*. But there is an additional layer of concern then a third stakeholder group is added (advertisers) who only experience the upside of increased data collection and none of the downside. And whom the platform has a strong financial motivation to impress (i.e. gain ad revenue).

I'm picturing a two step diagram.

In the first step there's a USER box and a COMPANY box with a line called data flowing from USER to COMPANY (Maybe the line is dashed because it's not essential). The data flow is a closed circuit (barring security breaches). The user expects that COMPANY to use the data for appropriate business uses (e.g. analytics, product development). Issues arise when the company collects data (or infers?) data that's unreasonable or inappropriate (e.g. Tim Hortons inferring your home) or data it was reasonable for it to collect is used in an unreasonable way (e.g. sold to a data broker). So there's a balance between improving the product and the user's right to privacy. *Maybe also lines of money from U to C and product from C to U?*

But then we have ad-based companies which I suggested in [Competition](/posts/competition.md) sell users' attention to advertisers. This add layers of privacy complexity.

USER box to COMPANY box to ADVERTISER box (then dashed line connected USER to ADVERTISER if A is already aware of U and had first party data on them)

There's no longer a line of money from U to C. The data line in now solid because the data is more important so that the C can *create* the product, rather than just optimising it. *There is no product without user data*.

There there's some kind of cycle because that data is used to develop the product to optimise user engagement (i.e. get more attention) which then creates more data. Not sure how to visualise that! So there's flow line from U to C of user attention.

Then a (user) attention flow line from C to A. And one for data. However that not exactly right because the platforms don't give the advertisers that data directly. Needs to be a second order product like 'tailoring' or something like that. Then money line from A to C. And a dotted line for first party user data (if they have).

There are two fundamental differences to the step above

1. Because users' don't pay for products, companies must use the resources available to gain income. This means 'selling' user attention to advertisers and using user data to do it more effectively.
2. For companies using user-generated content (esp social media but also marketplaces and others) *user data becomes part of the product*. It is not just used to optimise the product but there is no product without it.

Therefore strange new incentives are born. Users (unknowingly) trade their attention and data for the products. And the platforms use the data to gain more of users' attention. 

Because these features are fundamental to this new business model, a paradigm shift would be needed to move to a model that centres user privacy.

Attempting the diagram in a [miro flowchart](https://miro.com/app/board/uXjVOwZOjKY=/)

## Background

### Literature

What's the best evidence on how effect more targeted advertising is. E.g. what's the value trade off between privacy losses and advertising gains?

### Policy

Summary of GDPR

How do the new EU bills update?

What other countries have consumer privacy legislation?

Private right of action - The right of individuals to sue companies directly for violating their privacy rights. Vs the state having to be the one to sue.

## US Federal

It doesn't look like US federal regulation is coming to states are writing their own laws. The California law takes after an EU one. Whereas Utah and other states have introduced much more business-friendly laws.

Are consumer advocacy groups not doing enough advocacy? (https://www.protocol.com/policy/virginia-maryland-washington-big-tech). 'Ed Mierzwinski, a senior director at the U.S. Public Interest Research Group, said he and other national consumer and privacy groups didn't find out about this bill until a few weeks ago.' Feels like a cop-out. I appreciate that these groups have limited resources, but they need to be preemptive in learning what laws are on the horizon rather than waiting to be informed about them.

What is the FTC's privacy remit? New Commissioner Bedoya has a privacy background. He Founded the Center on Privacy and Technology at Georgetown.

The May 2022 FTC complaint against Twitter cites privacy concerns. It states that between 2014 and 2019 Twitter requested users provided their phone numbers and email addresses, stating they would be used for security purposes, but Twitter then also used that contact information to target advertising. The claim states that this was deceptive as Twitter 'buried' such notice in its privacy policy.
[On FTC’s Twitter Case: Enhancing Security Without Compromising Privacy](https://www.ftc.gov/policy/advocacy-research/tech-at-ftc/2022/05/ftcs-twitter-case-enhancing-security-without-compromising-privacy)

> Generic, broad claims buried in a lengthy document do not override more specific, just-in-time statements made to consumers specifically in the context of when they are providing their information – in this case, about the use of contact information for security purposes. If a company says at the point of collection that consumers’ information will be used for a particular purpose, consumers should be able to rely on that promise.

Having no experience with the FTC's approach to privacy concerns such a strong statement took my by surprise. It makes me feel quibbly by pointing out that Twitter didn't state at the point of collection that contact information would *only* be used for security purposes. From my 2022 vantage point it seems naive that a user wouldn't expect their contact information to be used for targeted advertising. But I am not the average user, and 2014 was a very different time.

They cite this as 'a basic tenet of consumer protection law' and reference the FTC’s “Dot.Com Disclosures” guidance':

> It is highly unlikely that consumers will read disclosures buried in ‘terms of use’ and similar lengthy agreements. Even if such agreements may be sufficient for contractual or other purposes, disclosures that are necessary to prevent deception or unfairness should not be relegated to them.  Similarly, simply because consumers click that they ‘agree’ to a term or condition, does not make the disclosure clear and conspicuous.

Also - again a positive surprise - it turns out the FTC has had guidelines on ['How to Make Effective Disclosures in Digital Advertising'](https://www.ftc.gov/sites/default/files/attachments/press-releases/ftc-staff-revises-online-advertising-disclosure-guidelines/130312dotcomdisclosures.pdf) since at least 2013!

In the Twitter complaint they include a 'novel feature' by requiring Twitter to allow users to use multi-factor authentication that does not require giving Twitter a phone number (e.g. via security keys or an authentication app).

## US State level

https://www.consumerprivacyact.com/

[Article on tech lobbying in Utah](https://themarkup.org/privacy/2022/05/26/tech-industry-groups-are-watering-down-attempts-at-privacy-regulation-one-state-at-a-time)

### California Privacy Protection Agency (CPPA)

CA introduced the California Privacy Rights Act (CPRA) of 2020 which established the agency. Built on the California Consumer Privacy Act (CCPA) of 2018 which was in some ways [inspired by GDPR](https://www.americanbar.org/groups/litigation/committees/minority-trial-lawyer/practice/2020/what-you-need-to-know-about-the-ccpa-and-the-european-unions-gdpr/).

[Global Privacy Control (GPC) technology](https://globalprivacycontrol.org/) developed to allow users to opt out of the 'sale' of their personal information. Works at the browser-level. A header is sent to the website which then must honor the opt out (in CA). In other jurisdictions websites pledge to respect the opt out.

### Other states
VA in 2021. The original draft of which was [written by an Amazon lobbyist](https://www.protocol.com/policy/virginia-maryland-washington-big-tech)

Washington Privacy Act failed to pass as of early 2022

2022 Connecticut enacts privacy legislation that mandates following global opt out signals.

Biometric Information Privacy Act of Illinois
- [How Illinois Is Winning in the Fight Against Big Tech](https://www.nytimes.com/2022/05/30/opinion/illinois-biometric-data-privacy.html)

## Forecasting

What will be the implications on the bifuracted state-based framework? Will it be messy or allow a marketplace of options?

    "Now, when I talk to state lawmakers or state staff members and say, 'Hey, it's a really bad idea to have a state patchwork of laws,' I just hear silence from them because they're like, 'Well, Congress still hasn't done anything,'" said Billy Easley, a senior tech policy analyst with Koch-backed Americans for Prosperity, which advocates against state-level legislation on privacy and speech.

Privacy rights should be inelastic - e.g. if a user is based in CA it shouldn't matter where the company is based. How the company collects and processes the user's data should fall under CA law.

The difficulty here is  double edge privacy sword - the company must know that the user is in CA to apply the CA laws. Therefore it requires the company to capture and process at least that level of location data. Is that something that the companies will actually have difficultly complying with.

Are the laws based on residence or current location. E.g. If I live in the UK and go to California on vacation, does UK or CA law apply when I'm in CA?

Because it's inelastic there could be a Brussels Effect. A motivation for the level of tech lobbying is to make sure a plurality of states have friendly regulation. If only two states were friendly and the rest were burdensome, then the Brussels effect would lead the companies to just harmonize to the higher standards to avoid having to maintain a complex network of product versions.

I suspect that the lobbying really ramped up after tech 'lost' California is that sense.

## Cast Studies

### Tim Horton's Location Tracking

In June 2022 the Offices of the Privacy Commissioners of Canada and the provinces of Alberta and British Columbia [announced a joint investigation](https://priv.gc.ca/en/opc-actions-and-decisions/investigations/investigations-into-businesses/2022/pipeda-2022-001/) into the use location tracking by coffee chain Tim Horton's app. The announcement cites a number of concerns

1. The app collected information of user location when the app was closed, even when the user had only granted access permissions while the app was in use
2. This was done 'to infer [the user's] home, place of work, travel status, and when he was visiting a competitor' for the purposes of targeted advertising.


## Paid for product selling user data to data broker?

## Paid for product using user data unreasonably?